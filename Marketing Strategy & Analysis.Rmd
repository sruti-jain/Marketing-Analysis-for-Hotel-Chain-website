---
title: "Marketing strategy guidelines for a hotels chain website"
output:
  html_document:
    css: AnalyticsStyles/default.css
    theme: paper
    includes:
      in_header: AnalyticsStyles/default.sty
always_allow_html: yes
#render("TravelProject.Rmd", html_document())
---
```{r setuplibraries, echo=FALSE, message=FALSE}
source("Library/Library.R")
source("Library/helpersSet1.R")
source("Library/helpersSet2.R")
source("Library/MartrixOperations.R")
```

### The Business Questions

Define martketing strategies to increase the revenues generated by the customers of the website though a better understanding of the customer segments.

### The Process

We followed a 3 steps process:

**Part 1**: Data set inspection and dimensionality reduction

**Part 2**: Data analysis and marketing insights

**Part 3**: Recommendation and next steps

<hr>\clearpage

# Part 1 - Data Inspection

### Key Customer Characteristics

First step: we load the data to use:

```{r, echo=FALSE, tidy=TRUE}
myData <- read.csv(file = "Data/AnalyticsData.csv", header = TRUE, sep=",")
MIN_VALUE = 0.5
```

The data refers to the users and their interaction with the website until that time.
Overall the dataset contains information on almost 1 million customers grouped in 667 types of customers described by 19 number of variables.

Variables description: <br>
<ul>
<li> Type of User: Returning or New Visitor </li>
<li> Source: Organic vs Paid Promotions (cpc, cpm, referral) </li>
<li> Users: Number of User Visits </li>
<li> Sessions: Number of User Sessions </li>
<li> No of Pages Visited: Number of total pages visited </li>
<li> No of Transactions: Number of monetary transactions </li>
<li> Revenue: Revenue generated </li>
<li> Dummy Variable: We created dummy variables categorical data such as 'user type', 'source' and 'device type'  </li>
</ul>
  

```{r}
factor_attributes_used = c(1:19)
factor_selectionciterion = 
minimum_variance_explained = 65
manual_numb_factors_used = 5
rotation_used = "varimax"
max_data_report = 5
factor_attributes_used <- intersect(factor_attributes_used, 1:ncol(myData))
ProjectDataFactor <- myData[,factor_attributes_used]
ProjectDataFactor <- as.matrix(ProjectDataFactor)
```

### Check the Data 

We start by doing a basic visual exploration of the first customer types:

<p align="center"> **Data Visualization** </p>

```{r, echo=FALSE, tidy=TRUE}
rownames(ProjectDataFactor) <- paste0("Customer", sprintf("%02i", 1:nrow(ProjectDataFactor)))
knitr::kable(t(head(ProjectDataFactor, max_data_report)))
```

### Check Correlations

We can then analyze the data in terms of correlation between different variables.
The objetctive is to get a first idea of possible cross-relationships between variables that could lead to a dimensionality reduction as a first step for the analysis.

<p align="center"> **Correlation Table** </p>

```{r, echo=FALSE, tidy=TRUE}
thecor = round(cor(myData[,4:19]),2)
knitr::kable(round(thecor,2), scale=TRUE)
```

From correlation matrix we can see that there is a relevant positive correlation between number of sessions, number of pages visited, number of transactions and revenues for each of the customer types.

This makes business sense, as it makes sense that the customer segment with more activity ends up generating higher revenues.

Another relevant insight is that Desktop device is the one that generates most of the traffic and revenues in absolute value.


### Choose number of factors

To use Factor Analysis, we first need to adjust data to have only numeric data.
We can then remove first columns and keep only binary values that describe the users types in the same manner.

```{r}
num_data <- myData[,4:ncol(myData)]
scaled_data <- apply(num_data,2, function(r) {if (sd(r)!=0) res=(r-mean(r))/sd(r) else res=0*r; res})
```

Now that we have only numeric data, we can proceed with Factor Analysis in order to do the Dimensionality Redcution.

```{r}
Variance_Explained_Table_results<-PCA(scaled_data, graph=FALSE)
Variance_Explained_Table<-Variance_Explained_Table_results$eig
Variance_Explained_Table<-as.data.frame(Variance_Explained_Table)
colnames(Variance_Explained_Table)<-c("Eigenvalue", "Percentage_of_explained_variance", "Cumulative_percentage_of_explained_variance")

eigenvalues  <- Variance_Explained_Table[,2]
```

The next step is to look at the **variance explained** as well as the **eigenvalues**

<p align="center"> **Variance Explained** </p>

```{r, echo=FALSE, tidy=TRUE}
iprint.df(round(Variance_Explained_Table, 2))
```

<p align="center"> **Eigenvalue Plot** </p>

```{r, echo=FALSE, tidy=TRUE}
eigenvalues  <- Variance_Explained_Table[, "Eigenvalue"]
df           <- cbind(as.data.frame(eigenvalues), c(1:length(eigenvalues)), rep(1, length(eigenvalues)))
colnames(df) <- c("eigenvalues", "components", "abline")
iplot.df(melt(df, id="components"))
```

### Interpret the Components

We can see from the chart above that we could use only 8 components (the ones with eigenvalue >1).
This number makes total sense as there are several binary variables that explain the same as the text variables. 
We can identify the following groups:

<ul>
<li> Device </li>
<li> Returning/New Visitor </li>
<li> Source </li>
<li> Revenues </li>
<li> Number of Sessions </li>
<li> Number of pages visited </li>
<li> Number of Users </li>
<li> Number of Transactions </li>
</ul>

In this case we suggest to keep all the original variables and not reduce the dimension since the higher number of binary variables are just a way to provide the same information in a numerical form.

<hr>\clearpage

# Part 2: Marketing insights from the data

To analyze different scenarios and identify possible strategies, we can focus on different behaviors across devices.

```{r}
averageTransaction <- aggregate(myData$No.of.Transactions,list(myData$Device), FUN=sum)
colnames(averageTransaction) <- c("Device","No of Transactions")
knitr::kable(averageTransaction)
```

We can clearly see that desktop is the main channel used by customers to access the website, generating about 95% of total transactions.
The next step is to analyze the revenue sources, to check if we find the same trend as in the number of transactions or if the behavior changes depending on the device used.

```{r}
averageRevenue <- aggregate(myData$Revenue,list(myData$Device), FUN=sum)
colnames(averageRevenue) <- c("Device","Revenues")
knitr::kable(averageRevenue)
```

The analysis on revenues shows that desktop is the device that generates more revenues, as expected from the previous result.
Now, we will analyze revenues per transaction to check if the "unitary" revenues per customer vary  depending on the type of device.

```{r}
RevTransaction <- averageRevenue
RevTransaction[,2] <- averageRevenue[,2]/averageTransaction[,2] 
colnames(RevTransaction) <- c("Device","Revenue per Transaction")
knitr::kable(RevTransaction)
```

We can see that revenues per transaction are quite stable cross-device, even though tablet is more profitable if compared to desktop and mobile devices.

Moving from devices to sources, we can then compare organic sources to payed sources (e.g. "cpc") and analyze the relationship between transactions and revenues depending on the different sources.


```{r}
averageTransactionSource <- aggregate(myData$No.of.Transactions,list(myData$Source), FUN=sum)
averageRevenueSource <- aggregate(myData$Revenue,list(myData$Source), FUN=sum)
RevTransactionSource <- averageRevenueSource
RevTransactionSource[,3] <- averageRevenueSource[,2]/averageTransactionSource[,2] 
RevTransactionSource[,2] <- averageRevenueSource[,2]
RevTransactionSource <- RevTransactionSource[order(RevTransactionSource[,2],RevTransactionSource[,1],decreasing=TRUE),]
rownames(RevTransactionSource) <- c(1:nrow(RevTransactionSource))
colnames(RevTransactionSource) <- c("Source","Revenue","Revenue/transaction")
knitr::kable(RevTransactionSource[1:10,])
```

In the table abover we are showing the top 10 sources of revenue and the average revenue per transaction.

The first relevant thing is the high average revenue per transaction. Analyzing the full data set we found more "reasonable" values for small sources, but all the top ones show high values. Our hypotheses is that some of the reservations might be done by agencies, which distorts the average figures.

The second insight is that among the top sources, the ones with direct access and organic searches on google or bing provide more than 4 times the revenues of payed sources like "cpc" and "cpm".

Finally, we see that the average revenue per transaction of direct access/organic searches is higher than the average revenue per transaction of payed sources.

<hr>\clearpage

# Part 3: Recommendation and next steps

From the previous analysis, we suggest the following guidelines for the marketing strategy:<br>

<ul>
<li> Improve the current App in order to increase the share of revenues from tablets and mobiles as they tend to have higher revenue per transaction </li>
<li> Optimize the expenditure in payed sources: focus on "dfa/cpc" as it has the higher revenue per transaction </li>
<li> Increase the awareness of potential customers to increase the direct / organic visits. Explore posibilities such as: TV and newspaper advertising, direct contact with travel agents </li>
</ul>

<br>
In order to implement the strategic recommendations and to analyze additional options, the following next steps are needed:<br>

<ul>
<li> To analyze additional options: Improve the quality of the data set by identifying the country of each customer and obtaining additional data: employment, age, etc. This would allow to make more targeted campaigns in the future </li>
<li> Before implementing recommendations: Analyze the costs of the payed sources by type/country and do a cost/benefit analysis to determine the ROI and NPV of each source. Then optimize the marketing budget with the objective of maximizing the NPV of that budget </li>